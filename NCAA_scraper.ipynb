{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd3a525-826f-40c5-b578-137aa120b531",
   "metadata": {
    "id": "bdd3a525-826f-40c5-b578-137aa120b531",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f66bf102-f46c-453d-ae0b-580e511a7a17",
   "metadata": {
    "id": "f66bf102-f46c-453d-ae0b-580e511a7a17",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate a list of all of the dates in the season\n",
    "\n",
    "date_list = [datetime.datetime(2022, 8, 26) + datetime.timedelta(days=x) for x in range(87)]\n",
    "\n",
    "## itterates the list of dates and retrives all compiles a url for each day\n",
    "pages = [f\"http://stats.ncaa.org/season_divisions/17902/livestream_scoreboards?utf8=✓&season_division_id=&game_date={date_list[x].month}%2F{date_list[x].day}%2F2022&conference_id=0&tournament_id=&commit=Submit\" for x,n in enumerate(date_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad0829e7-c828-4de1-b7ae-02e35f3ebd1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "ad0829e7-c828-4de1-b7ae-02e35f3ebd1c",
    "outputId": "8e320f86-13f4-4f65-c8d1-cfa42c61c4e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 87/87 [01:49<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# loop to itterate through url generated above and retrive all box scores to all games on that day\n",
    "\n",
    "box_scores = [] \n",
    "for page in tqdm(pages):\n",
    "\n",
    "    url = page\n",
    "\n",
    "    header = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',\n",
    "    }\n",
    "\n",
    "    response = requests.get(url,headers=header)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all table rows\n",
    "    rows = soup.find_all('tr')\n",
    "    \n",
    "    res = [row.find_all('a',string='Box Score') for row in rows]\n",
    "    res = list(filter(lambda a: a != [], res))\n",
    "    \n",
    "    box_scores+=([f\"http://stats.ncaa.org{el[0].get('href')}\" for el in res]) # make list of urls to box scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd9e9f0-e211-49cf-a3bf-984cdde1d1b1",
   "metadata": {
    "id": "0dd9e9f0-e211-49cf-a3bf-984cdde1d1b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                      | 62/773 [01:22<14:24,  1.22s/it]"
     ]
    }
   ],
   "source": [
    "all_games = [] # define list\n",
    "\n",
    "for target in tqdm(box_scores): # itterate through list of box score addresses\n",
    "\n",
    "\n",
    "    header = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',\n",
    "        } # ncaa will block if there is no user agent\n",
    "\n",
    "    response = requests.get(target,headers=header)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    #pbp link\n",
    "    pbp_link = f\"http://stats.ncaa.org{soup.find('a',string='Play by Play').get('href')}\"\n",
    "\n",
    "\n",
    "    # Find the table element\n",
    "    tables = soup.find_all('table', class_='mytable')\n",
    "\n",
    "    # Create an empty list to store the data\n",
    "    datas = []\n",
    "    datah = []\n",
    "    dataa = []\n",
    "\n",
    "    # Find all rows in the three tables\n",
    "    rowss = tables[0].find_all('tr')\n",
    "    rowsh = tables[1].find_all('tr')\n",
    "    rowsa = tables[2].find_all('tr')\n",
    "\n",
    "    # Loop through each row and extract the cell values from the tables\n",
    "    for row in rowss:\n",
    "        cells = row.find_all('td')\n",
    "        row_data = [cell.text.strip() for cell in cells]\n",
    "        datas.append(row_data)\n",
    "\n",
    "    for row in rowsh:\n",
    "        cells = row.find_all('td')\n",
    "        row_data = [cell.text.strip() for cell in cells]\n",
    "        datah.append(row_data)\n",
    "\n",
    "    for row in rowsa:\n",
    "        cells = row.find_all('td')\n",
    "        row_data = [cell.text.strip() for cell in cells]\n",
    "        dataa.append(row_data)\n",
    "\n",
    "\n",
    "    df_sum = pd.DataFrame(datas)\n",
    "    df_home = pd.DataFrame(datah)\n",
    "    df_away = pd.DataFrame(dataa)\n",
    "\n",
    "    df_home = df_home[2:-1]\n",
    "    df_away = df_away[2:-1]\n",
    "\n",
    "    target = pbp_link # make another request, retriving the play by play\n",
    "    response = requests.get(target,headers=header)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    tables = soup.find_all('table', class_='mytable')\n",
    "\n",
    "    pbp = []\n",
    "    for table in tables: # get all rows from all tables\n",
    "\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            row_data = [cell.text.strip() for cell in cells]\n",
    "            pbp.append(row_data)\n",
    "\n",
    "    pbp = pbp[4:-1] # chop head and tail off\n",
    "\n",
    "    pbp = list(filter(lambda a: len(a) > 1, pbp)) # only incude rows with more than one element\n",
    "    pbp = list(filter(lambda a: a[0] != 'Time', pbp)) # do not include column head rows\n",
    "\n",
    "    data = {'url':target,'df_sum':df_sum,'df_home':df_home,'df_away':df_away,'pbp':pbp} # assemble dict\n",
    "    \n",
    "    all_games.append(data) # add to list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z50yK397-qtw",
   "metadata": {
    "id": "Z50yK397-qtw"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zdL44FRWDnz5",
   "metadata": {
    "id": "zdL44FRWDnz5"
   },
   "outputs": [],
   "source": [
    "# Save data as a file\n",
    "with open(''Documents/GitHub/NCAA-fh-project/results.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
